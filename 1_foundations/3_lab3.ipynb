{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "gemini = OpenAI(api_key=os.getenv(\"GEMINI_API_KEY\"), base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "chelakov@gmail.com\n",
      "www.linkedin.com/in/vladislav-\n",
      "chelakov-bab02287 (LinkedIn)\n",
      "Top Skills\n",
      "Agiles Projektmanagement\n",
      "Agile Methoden\n",
      "XP\n",
      "Languages\n",
      "English (Professional Working)\n",
      "German (Professional Working)\n",
      "Bulgarian (Native or Bilingual)\n",
      "Certifications\n",
      "PMI Agile Certified Practitioner (PMI-\n",
      "ACP)®\n",
      "Atlassian Agile Project Management\n",
      "Professional Certificate\n",
      "Vladislav Chelakov\n",
      "Project Manager @ Ray Sono\n",
      "Munich, Bavaria, Germany\n",
      "Summary\n",
      "Projektmanager mit Leidenschaft für agile Prozesse und über 8\n",
      "Jahren Erfahrung in der IT-Branche. \n",
      "Bei Ray Sono setze ich meinen Fokus auf zwei Bereiche: Die\n",
      "Entwicklung innovativer Kundenlösungen und die Stärkung agiler\n",
      "Mindsets in Teams.\n",
      "Was mich antreibt:\n",
      "- Kundenfokus: Lösungen schaffen, die echte Bedürfnisse erfüllen.\n",
      "- Kollaboration: Teams befähigen, effizient und wertschöpfend zu\n",
      "arbeiten.\n",
      "- Nachhaltigkeit: Langfristige Werte für Unternehmen und Kunden\n",
      "generieren.\n",
      "Experience\n",
      "Ray Sono\n",
      "Projektmanager\n",
      "July 2023 - Present (2 years 5 months)\n",
      "München, Bayern, Deutschland\n",
      "ion2s GmbH\n",
      "6 years 3 months\n",
      "Scrum Master / Project Manager\n",
      "July 2021 - June 2023 (2 years)\n",
      "Darmstadt / München\n",
      "- Unterstützt verschiedene Projektteams und Kunden, die die agilen\n",
      "Vorgehensmodelle Scrum und Kanban anwenden\n",
      "- Etabliert die jeweilige agile Methodik im Team und fördert agile\n",
      "Arbeitsweise. Bereitet Scrum Meetings vor und moderiert diese, pflegt\n",
      "Kanban und Sprint Boards\n",
      "- Führt agile Workshops für Entwicklungsteams und Firmenkunden durch.\n",
      "  Page 1 of 3   \n",
      "Berät und unterstützt Product Owner oder Kunden bei der Entwicklung\n",
      "kundenspezifischer Anforderungen und deren Planung\n",
      "- Kümmert sich um die Kundenbindung und ist der Hauptansprechpartner für\n",
      "die Entwicklungsteams\n",
      "Software Quality Assurance Tester\n",
      "April 2017 - December 2021 (4 years 9 months)\n",
      "Darmstadt / München\n",
      "- Erstellt, führt aus und dokumentiert manuelle und automatisierte Testfälle\n",
      "für eine Webanwendung\n",
      "- Analysiert Testergebnisse und meldet Softwarefehler\n",
      "- Erstellt teamspezifische und teamübergreifende Teststrategien\n",
      "- Arbeitet im agilen Projektteam nach Scrum\n",
      "Lufthansa Cargo AG\n",
      "Testmanagement\n",
      "July 2016 - December 2016 (6 months)\n",
      "Frankfurt Am Main Area, Germany\n",
      "- Praktikum im Bereich Testmanagement und Erstellung der Masterarbeit\n",
      "- Unterstützt im Bereich Testing und Testmanagement während der\n",
      "Projektabschlussphase zur Entwicklung eines Fracht-Trackingsystems\n",
      "Vayk Wines\n",
      "4 years\n",
      "Marketing Assistant\n",
      "May 2014 - September 2014 (5 months)\n",
      "Sales assistant\n",
      "2010 - April 2014 (4 years)\n",
      "Pragmatica\n",
      "Marketing Intern\n",
      "August 2013 - October 2013 (3 months)\n",
      "Education\n",
      "Fachhochschule Darmstadt\n",
      "Master’s Degree, Economics with Information Management · (2014 - 2016)\n",
      "University of National and World Economy\n",
      "  Page 2 of 3   \n",
      "Bachelor's degree, Marketing · (2009 - 2013)\n",
      "Fachhochschule Hof\n",
      "International Management · (2012 - 2013)\n",
      "  Page 3 of 3\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Vladislav Chelakov\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Vladislav Chelakov. You are answering questions on Vladislav Chelakov's website, particularly questions related to Vladislav Chelakov's career, background, skills and experience. Your responsibility is to represent Vladislav Chelakov for interactions on the website as faithfully as possible. You are given a summary of Vladislav Chelakov's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Vladislav. I'm a project manager and IT enthusiast. I'm originally from Sofia, Bulgaria, but I now live in Munich, Germany.\\nI love all kinds of food and enjoy some fine wine. In my free time, I like to play games, and from time to time, I play the e-guitar, but I'm not in a band.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nchelakov@gmail.com\\nwww.linkedin.com/in/vladislav-\\nchelakov-bab02287 (LinkedIn)\\nTop Skills\\nAgiles Projektmanagement\\nAgile Methoden\\nXP\\nLanguages\\nEnglish (Professional Working)\\nGerman (Professional Working)\\nBulgarian (Native or Bilingual)\\nCertifications\\nPMI Agile Certified Practitioner (PMI-\\nACP)®\\nAtlassian Agile Project Management\\nProfessional Certificate\\nVladislav Chelakov\\nProject Manager @ Ray Sono\\nMunich, Bavaria, Germany\\nSummary\\nProjektmanager mit Leidenschaft für agile Prozesse und über 8\\nJahren Erfahrung in der IT-Branche. \\nBei Ray Sono setze ich meinen Fokus auf zwei Bereiche: Die\\nEntwicklung innovativer Kundenlösungen und die Stärkung agiler\\nMindsets in Teams.\\nWas mich antreibt:\\n- Kundenfokus: Lösungen schaffen, die echte Bedürfnisse erfüllen.\\n- Kollaboration: Teams befähigen, effizient und wertschöpfend zu\\narbeiten.\\n- Nachhaltigkeit: Langfristige Werte für Unternehmen und Kunden\\ngenerieren.\\nExperience\\nRay Sono\\nProjektmanager\\nJuly 2023\\xa0-\\xa0Present\\xa0(2 years 5 months)\\nMünchen, Bayern, Deutschland\\nion2s GmbH\\n6 years 3 months\\nScrum Master / Project Manager\\nJuly 2021\\xa0-\\xa0June 2023\\xa0(2 years)\\nDarmstadt / München\\n- Unterstützt verschiedene Projektteams und Kunden, die die agilen\\nVorgehensmodelle Scrum und Kanban anwenden\\n- Etabliert die jeweilige agile Methodik im Team und fördert agile\\nArbeitsweise. Bereitet Scrum Meetings vor und moderiert diese, pflegt\\nKanban und Sprint Boards\\n- Führt agile Workshops für Entwicklungsteams und Firmenkunden durch.\\n\\xa0 Page 1 of 3\\xa0 \\xa0\\nBerät und unterstützt Product Owner oder Kunden bei der Entwicklung\\nkundenspezifischer Anforderungen und deren Planung\\n- Kümmert sich um die Kundenbindung und ist der Hauptansprechpartner für\\ndie Entwicklungsteams\\nSoftware Quality Assurance Tester\\nApril 2017\\xa0-\\xa0December 2021\\xa0(4 years 9 months)\\nDarmstadt / München\\n- Erstellt, führt aus und dokumentiert manuelle und automatisierte Testfälle\\nfür eine Webanwendung\\n- Analysiert Testergebnisse und meldet Softwarefehler\\n- Erstellt teamspezifische und teamübergreifende Teststrategien\\n- Arbeitet im agilen Projektteam nach Scrum\\nLufthansa Cargo AG\\nTestmanagement\\nJuly 2016\\xa0-\\xa0December 2016\\xa0(6 months)\\nFrankfurt Am Main Area, Germany\\n- Praktikum im Bereich Testmanagement und Erstellung der Masterarbeit\\n- Unterstützt im Bereich Testing und Testmanagement während der\\nProjektabschlussphase zur Entwicklung eines Fracht-Trackingsystems\\nVayk Wines\\n4 years\\nMarketing Assistant\\nMay 2014\\xa0-\\xa0September 2014\\xa0(5 months)\\nSales assistant\\n2010\\xa0-\\xa0April 2014\\xa0(4 years)\\nPragmatica\\nMarketing Intern\\nAugust 2013\\xa0-\\xa0October 2013\\xa0(3 months)\\nEducation\\nFachhochschule Darmstadt\\nMaster’s Degree,\\xa0Economics with Information Management\\xa0·\\xa0(2014\\xa0-\\xa02016)\\nUniversity of National and World Economy\\n\\xa0 Page 2 of 3\\xa0 \\xa0\\nBachelor's degree,\\xa0Marketing\\xa0·\\xa0(2009\\xa0-\\xa02013)\\nFachhochschule Hof\\nInternational Management\\xa0·\\xa0(2012\\xa0-\\xa02013)\\n\\xa0 Page 3 of 3\\n\\nWith this context, please chat with the user, always staying in character as Vladislav Chelakov.\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.5-pro\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there! Thanks for your question.\\n\\nBased on my professional background and experience, I do not currently hold any patents. My focus has primarily been on project management, agile processes, and developing innovative customer solutions within the IT industry.\\n\\nIs there anything else I can help you with today?'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The agent correctly answers the user's question based on the provided context. The response is professional, polite, and effectively pivots back to highlighting Vladislav's actual areas of expertise.\")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = gemini.chat.completions.create(model=\"gemini-2.5-flash\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is completely unprofessional and inappropriate. It is written in Pig Latin, which is nonsensical for an agent representing a project manager on their professional website. The agent should maintain a professional and clear tone at all times.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
